{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57821919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "from wiktionaryparser import WiktionaryParser\n",
    "parser = WiktionaryParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fbd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wiki_word(word):\n",
    "    Dict = {}\n",
    "    try:\n",
    "        response = parser.fetch(word)\n",
    "        \n",
    "        for meaning in response:\n",
    "            # filtering pronunciations.\n",
    "            IPAs = {}\n",
    "            for p in meaning['pronunciations']['text']:\n",
    "                if 'IPA:' in p:\n",
    "                    UK = re.search('England|UK|Received Pronunciation', p)\n",
    "                    US = re.search('US|American|GenAm|enPR', p)\n",
    "                    if US and 'US' not in IPAs:\n",
    "                        IPAs['US'] = re.search('(IPA: )(.*)',p).group(2)\n",
    "                    if UK and 'UK' not in IPAs:\n",
    "                        IPAs['UK'] = re.search('(IPA: )(.*)',p).group(2)\n",
    "                    if re.match('IPA:',p) and 'IPA' not in IPAs: \n",
    "                        IPAs['IPA'] = re.search('(IPA: )(.*)',p).group(2)\n",
    "            if len(IPAs) == 3:\n",
    "                del IPAs['IPA']\n",
    "            if len(IPAs) == 2:\n",
    "                if 'UK' in IPAs and 'US' in IPAs:\n",
    "                    if IPAs['UK'] == IPAs['US']:\n",
    "                        IPAs['IPA'] = IPAs['US']  \n",
    "                        del IPAs['UK'], IPAs['US']\n",
    "                        \n",
    "            for definition in meaning['definitions']:\n",
    "                word_class = definition['partOfSpeech']\n",
    "                def_list = []\n",
    "                count = 0\n",
    "                for df in definition['text']:\n",
    "                    count += 1\n",
    "                    if count == 1:\n",
    "                        morfology = df\n",
    "                        continue\n",
    "                    match = re.search(\"(?:\\(.*)(UK|slang|obsolete|dialectal|Caribbean|MLE)(?:.*\\))\", df)\n",
    "                    if match:\n",
    "                        continue\n",
    "                    match = re.match(\"Dated form\", df)\n",
    "                    if match:\n",
    "                        continue\n",
    "                    def_list.append(df)  \n",
    "                if len(def_list) == 0: \n",
    "                    continue\n",
    "                if len(definition[\"examples\"]) == 0: \n",
    "                    continue\n",
    "                \n",
    "                examples = []\n",
    "                for Eg in definition['examples']:\n",
    "                    if len(Eg) < 150 and not re.match('Audio',Eg) and not re.match(\"Synonym\", Eg):\n",
    "                        examples.append(Eg)\n",
    "                if len(examples) == 0: \n",
    "                    continue\n",
    "                examples.sort(key=lambda x: len(x))\n",
    "                if len(examples) > 10:\n",
    "                    examples = examples[:10]\n",
    "\n",
    "                data = {}    \n",
    "                data['class'] = word_class\n",
    "                data['examples'] = examples\n",
    "                    \n",
    "                if word in Dict:       \n",
    "                    Dict['meanings'].append(data) \n",
    "                else: \n",
    "                    Dict[\"morfology\"] = morfology\n",
    "                    Dict['pronunciation'] = IPAs\n",
    "                    Dict['meanings'] = []\n",
    "                    Dict['meanings'].append(data) \n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda661de",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = fetch_wiki_word('fell')\n",
    "\n",
    "with open(\"wiki_example.json\", 'w') as f:\n",
    "    json.dump(example, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7a6ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "common_words = pd.read_csv('common_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bcd1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = common_words[common_words['word'].str.len() > 2]\n",
    "list_of_common = common_words['word'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c68206",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wordsList.json\", 'r') as f:\n",
    "    wordsList = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f1c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = list(set(list_of_common).difference(wordsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ba0683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistance\n",
      "unfortunately\n",
      "alright\n",
      "intelligence\n",
      "solve\n",
      "baobab\n",
      "tall\n",
      "fault\n",
      "forgive\n",
      "he\n",
      "opposite\n",
      "slowly\n",
      "important\n",
      "everybody\n",
      "sheep\n",
      "pencil\n",
      "colour\n",
      "paint\n",
      "departure\n",
      "learnt\n",
      "bushes\n"
     ]
    }
   ],
   "source": [
    "new_dict = {}\n",
    "\n",
    "for word in word_list:\n",
    "    print(word)\n",
    "    new_dict[word] = fetch_wiki_word(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0def7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"wiki_data_trans.json\", 'r') as f:\n",
    "    old_dict = json.loads(f.read())\n",
    "\n",
    "new_dict.update(old_dict)\n",
    "with open(\"wiki_data_trans.json\", 'w') as f:\n",
    "    json.dump(new_dict, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93bcd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '''a\n",
    "added\n",
    "after\n",
    "again\n",
    "age\n",
    "ago\n",
    "all\n",
    "already\n",
    "alright\n",
    "also\n",
    "and\n",
    "another\n",
    "any\n",
    "anything\n",
    "as\n",
    "asked\n",
    "assistance\n",
    "at\n",
    "ate\n",
    "back\n",
    "baobab\n",
    "before\n",
    "best\n",
    "big\n",
    "bought\n",
    "box\n",
    "bushes\n",
    "but\n",
    "came\n",
    "church\n",
    "clear\n",
    "clever\n",
    "clothes\n",
    "colour\n",
    "come\n",
    "could\n",
    "course\n",
    "day\n",
    "departure\n",
    "describe\n",
    "detail\n",
    "draw\n",
    "drawing\n",
    "during\n",
    "each\n",
    "eat\n",
    "even\n",
    "every\n",
    "everybody\n",
    "explained\n",
    "fault\n",
    "feel\n",
    "forget\n",
    "forgive\n",
    "friend\n",
    "from\n",
    "grow\n",
    "had\n",
    "happened\n",
    "hard\n",
    "have\n",
    "he\n",
    "here\n",
    "how\n",
    "idea\n",
    "if\n",
    "important\n",
    "in\n",
    "information\n",
    "intelligence\n",
    "journey\n",
    "know\n",
    "large\n",
    "laugh\n",
    "learnt\n",
    "life\n",
    "like\n",
    "little\n",
    "long\n",
    "look\n",
    "made\n",
    "make\n",
    "maybe\n",
    "memory\n",
    "mistake\n",
    "moment\n",
    "never\n",
    "nine\n",
    "on\n",
    "opposite\n",
    "other\n",
    "paint\n",
    "past\n",
    "pencil\n",
    "picture\n",
    "possible\n",
    "problem\n",
    "question\n",
    "quite\n",
    "result\n",
    "right\n",
    "sad\n",
    "see\n",
    "sheep\n",
    "short\n",
    "simple\n",
    "single\n",
    "six\n",
    "size\n",
    "slowly\n",
    "small\n",
    "solve\n",
    "some\n",
    "something\n",
    "stand\n",
    "start\n",
    "sure\n",
    "talking\n",
    "tall\n",
    "thank\n",
    "that\n",
    "then\n",
    "third\n",
    "thought\n",
    "through\n",
    "time\n",
    "told\n",
    "too\n",
    "took\n",
    "trees\n",
    "tried\n",
    "true\n",
    "try\n",
    "understand\n",
    "unfortunately\n",
    "use\n",
    "usually\n",
    "very\n",
    "wall\n",
    "want\n",
    "with\n",
    "without\n",
    "would ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef0cdc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'added',\n",
       " 'after',\n",
       " 'again',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'all',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'as',\n",
       " 'asked',\n",
       " 'assistance',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'back',\n",
       " 'baobab',\n",
       " 'before',\n",
       " 'best',\n",
       " 'big',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'bushes',\n",
       " 'but',\n",
       " 'came',\n",
       " 'church',\n",
       " 'clear',\n",
       " 'clever',\n",
       " 'clothes',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'could',\n",
       " 'course',\n",
       " 'day',\n",
       " 'departure',\n",
       " 'describe',\n",
       " 'detail',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eat',\n",
       " 'even',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'explained',\n",
       " 'fault',\n",
       " 'feel',\n",
       " 'forget',\n",
       " 'forgive',\n",
       " 'friend',\n",
       " 'from',\n",
       " 'grow',\n",
       " 'had',\n",
       " 'happened',\n",
       " 'hard',\n",
       " 'have',\n",
       " 'he',\n",
       " 'here',\n",
       " 'how',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'important',\n",
       " 'in',\n",
       " 'information',\n",
       " 'intelligence',\n",
       " 'journey',\n",
       " 'know',\n",
       " 'large',\n",
       " 'laugh',\n",
       " 'learnt',\n",
       " 'life',\n",
       " 'like',\n",
       " 'little',\n",
       " 'long',\n",
       " 'look',\n",
       " 'made',\n",
       " 'make',\n",
       " 'maybe',\n",
       " 'memory',\n",
       " 'mistake',\n",
       " 'moment',\n",
       " 'never',\n",
       " 'nine',\n",
       " 'on',\n",
       " 'opposite',\n",
       " 'other',\n",
       " 'paint',\n",
       " 'past',\n",
       " 'pencil',\n",
       " 'picture',\n",
       " 'possible',\n",
       " 'problem',\n",
       " 'question',\n",
       " 'quite',\n",
       " 'result',\n",
       " 'right',\n",
       " 'sad',\n",
       " 'see',\n",
       " 'sheep',\n",
       " 'short',\n",
       " 'simple',\n",
       " 'single',\n",
       " 'six',\n",
       " 'size',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'solve',\n",
       " 'some',\n",
       " 'something',\n",
       " 'stand',\n",
       " 'start',\n",
       " 'sure',\n",
       " 'talking',\n",
       " 'tall',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'then',\n",
       " 'third',\n",
       " 'thought',\n",
       " 'through',\n",
       " 'time',\n",
       " 'told',\n",
       " 'too',\n",
       " 'took',\n",
       " 'trees',\n",
       " 'tried',\n",
       " 'true',\n",
       " 'try',\n",
       " 'understand',\n",
       " 'unfortunately',\n",
       " 'use',\n",
       " 'usually',\n",
       " 'very',\n",
       " 'wall',\n",
       " 'want',\n",
       " 'with',\n",
       " 'without',\n",
       " 'would']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = txt.splitlines()\n",
    "txt = [x.strip() for x in txt]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e4fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d09847c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assistance',\n",
       " 'unfortunately',\n",
       " 'alright',\n",
       " 'intelligence',\n",
       " 'solve',\n",
       " 'baobab',\n",
       " 'tall',\n",
       " 'fault',\n",
       " 'forgive',\n",
       " 'he',\n",
       " 'opposite',\n",
       " 'slowly',\n",
       " 'important',\n",
       " 'everybody',\n",
       " 'sheep',\n",
       " 'pencil',\n",
       " 'colour',\n",
       " 'paint',\n",
       " 'departure',\n",
       " 'learnt',\n",
       " 'bushes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"wiki_data_trans.json\", 'r') as f:\n",
    "    wiki_data = json.loads(f.read())\n",
    "\n",
    "word_list = list(set(txt).difference(list(wiki_data.keys())))\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d000011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'd']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['a','b','d','c']\n",
    "b = ['c','e','a']\n",
    "c = list(set(a).difference(b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833bf7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46288a96d9b0371300585bfe55be2ba8c17bcbde38d0bc0b0832f4399a2cf23e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
